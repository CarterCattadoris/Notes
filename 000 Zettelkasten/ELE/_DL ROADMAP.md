# Deep Learning in Engineering Applications Roadmap

## 1. Neuron Foundations
- [[Linear Neuron]]
    - [[Supervised Learning in Linear Neuron]]
- [[Nonlinear Neuron]]
- [[Activation Functions]]

## 2. Supervised Learning & Feedforward Networks
- [[Supervised Learning]]
    - [[Gradient Descent]]
    - [[Learning Rate]]
    - [[Momentum]]
    - [[Mean Squared Error]]
- [[Feedforward Neural Network]]
    - [[Linear Feedforward Neural Network]]
    - [[Nonlinear Feedforward Neural Network]]
    - [[Backpropagation]]
    - [[Hyperparameters]]

## 3. Classification & Linear Separability
- [[Perceptron]]
- [[Binary Classification]]
    - [[Linear Separability]]
- [[Multi-class Classification]]

## 4. Unsupervised Learning & Clustering
- [[Unsupervised Learning]]
- [[Clustering]]
    - [[K-Means Algorithm]]
    - [[DBSCAN]]

## 5. Associative & Competitive Networks
- [[Hamming Network]]
    - [[Hamming Distance]]
- [[Maxnet]]
- [[Competitive Learning Network]]
    - [[Simple Competitive Learning Network]]
    - [[Vector Quantization]]
    - [[Voronoi Regions]]

## 6. Reinforcement Learning
- [[Reinforcement Learning]]
    - [[Exploration vs Exploitation]]
    - [[n-armed bandit]]
    - Q-Learning
    - Policy gradient methods
    - Reward functions
    - Markov decision processes

## 7. Convolutional Neural Networks (CNNs)
- Convolutional layers
    - Filters and kernels
    - Stride and padding
    - Feature maps
- Pooling layers
    - Max pooling
    - Average pooling
- CNN architectures
    - LeNet
    - AlexNet
    - VGG
    - ResNet
    - Inception
- Applications in computer vision
    - Image classification
    - Object detection
    - Semantic segmentation

## 8. Recurrent Neural Networks (RNNs)
- RNN fundamentals
    - Temporal sequences
    - Hidden states
- Vanishing and exploding gradients
- Long Short-Term Memory (LSTM)
    - Gates (forget, input, output)
    - Cell state
- Gated Recurrent Units (GRU)
- Bidirectional RNNs
- Applications
    - Time series prediction
    - Natural language processing
    - Speech recognition

## 9. Autoencoders
- Autoencoder architecture
    - Encoder and decoder
    - Bottleneck layer
- Dimensionality reduction
- Denoising autoencoders
- Variational autoencoders (VAE)
- Applications
    - Feature learning
    - Anomaly detection
    - Data compression

## 10. Generative Models
- Generative adversarial networks (GANs)
    - Generator and discriminator
    - Adversarial training
    - Mode collapse
- GAN variants
    - DCGAN
    - StyleGAN
    - Conditional GAN
- Diffusion models
- Applications in synthesis

## 11. Advanced Topics
- Transfer learning
    - Pre-trained models
    - Fine-tuning
- Regularization techniques
    - Dropout
    - Batch normalization
    - Data augmentation
    - L1/L2 regularization
- Optimization algorithms
    - SGD variants
    - Adam, RMSprop, AdaGrad
- Attention mechanisms
    - Self-attention
    - Multi-head attention
- Transformers
    - Encoder-decoder architecture
    - Positional encoding

## 12. Practical Considerations
- Dataset preparation
    - Train/validation/test splits
    - Cross-validation
- Model evaluation metrics
    - Accuracy, precision, recall, F1-score
    - Confusion matrix
    - ROC curves and AUC
- Overfitting and underfitting
- Hardware acceleration
    - GPU computing
    - TPUs
- Deep learning frameworks
    - TensorFlow
    - PyTorch
    - Keras
