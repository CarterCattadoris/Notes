202601291508
Status: #idea
Tags: [[Reinforcement Learning]], [[Deep Learning (ELE400)]]

**Exploration vs Exploitation** is a fundamental dilemma in [[Reinforcement Learning]] that does not exist in [[Supervised Learning]] or [[Unsupervised Learning]].

The agent must balance two conflicting objectives:
1.  **Exploitation ("Greedy")**: Selecting the action that currently has the highest estimated value.
    -   *Goal*: Maximize short-term reward using current knowledge.
    -   *Risk*: Getting stuck in a suboptimal strategy.
2.  **Exploration ("Non-Greedy")**: Selecting an action that does *not* have the highest current estimate.
    -   *Goal*: Improve estimates of other actions' values.
    -   *Benefit*: Potential to discover better long-term strategies.

Effective RL algorithms must balance these two to maximize cumulative reward over time.
