202601281004
Status: #idea
Tags: [[Deep Learning (ELE400)]]

A neural network where information flows in one direction: input to output

### Structure
- **Input Layer**: Receives input data
- **Hidden Layer(s)**: Intermediate processing
- **Output Layer**: Produces final result

### Types
- [[Linear Feedforward Neural Network]] - all neurons linear
- [[Nonlinear Feedforward Neural Network]] - contains nonlinear activation

### Key Property
For function approximation:
- Only 1 hidden layer is theoretically needed (Universal Approximation Theorem)
- More hidden neurons = better approximation of complex functions
- "Deep" networks have many hidden layers (e.g., GPT-3 has 96 layers)

### GPT-3 Parameters
- Layers: 96
- Hidden Nodes: >12,000
- Parameters: 175 billion
- Sequence length: 2048

---
### References
